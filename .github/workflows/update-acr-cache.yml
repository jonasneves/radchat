name: Update ACR Cache

on:
  workflow_dispatch:
    inputs:
      force:
        description: 'Force full update'
        type: boolean
        default: false
  schedule:
    # Run daily at 3am UTC during initial scraping, then weekly once complete
    - cron: '0 3 * * *'

jobs:
  update-cache:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup data branch
        run: |
          git fetch origin data:data 2>/dev/null || true
          if git rev-parse --verify data >/dev/null 2>&1; then
            git checkout data
          else
            git checkout --orphan data
            git rm -rf . 2>/dev/null || true
          fi
          mkdir -p src/data

      - name: Check if update needed
        id: need_update
        run: |
          FORCE="${{ github.event.inputs.force }}"
          if [ "$FORCE" = "true" ]; then
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "reason=force" >> $GITHUB_OUTPUT
            echo "Force update requested"
            exit 0
          fi

          if [ ! -f src/data/acr_criteria.json ]; then
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "reason=no_cache" >> $GITHUB_OUTPUT
            echo "No cache file, running initial scrape"
            exit 0
          fi

          # Check scrape state
          PENDING=$(python3 -c "
          import json
          data = json.load(open('src/data/acr_criteria.json'))
          topics = data.get('topics', {})
          pending = sum(1 for t in topics.values() if t.get('status') in ('pending', 'failed', None))
          print(pending)
          " 2>/dev/null || echo "0")

          echo "Pending topics: $PENDING"

          if [ "$PENDING" -gt 0 ]; then
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "reason=pending" >> $GITHUB_OUTPUT
            echo "Has pending topics to scrape"
            exit 0
          fi

          # Check age for weekly refresh
          UPDATED=$(python3 -c "import json; print(json.load(open('src/data/acr_criteria.json')).get('updated_at', ''))" 2>/dev/null || echo "")
          if [ -n "$UPDATED" ]; then
            AGE_DAYS=$(python3 -c "
          from datetime import datetime, timezone
          updated = datetime.fromisoformat('$UPDATED'.replace('Z', '+00:00'))
          age = (datetime.now(timezone.utc) - updated).days
          print(age)
          " 2>/dev/null || echo "999")
            echo "Cache is $AGE_DAYS days old"
            if [ "$AGE_DAYS" -lt 7 ]; then
              echo "skip=true" >> $GITHUB_OUTPUT
              echo "Cache is recent and no pending, skipping"
              exit 0
            fi
          fi

          echo "skip=false" >> $GITHUB_OUTPUT
          echo "reason=weekly" >> $GITHUB_OUTPUT

      - uses: actions/setup-python@v5
        if: steps.need_update.outputs.skip != 'true'
        with:
          python-version: '3.11'

      - name: Install dependencies
        if: steps.need_update.outputs.skip != 'true'
        run: pip install requests beautifulsoup4

      - name: Update ACR cache
        if: steps.need_update.outputs.skip != 'true'
        run: |
          # Copy existing cache if present
          if [ -f src/data/acr_criteria.json ]; then
            cp src/data/acr_criteria.json /tmp/existing_cache.json
          fi

          git show main:scripts/update_acr_cache.py > update_acr_cache.py
          python update_acr_cache.py

          # Restore cache location if script wrote elsewhere
          if [ -f /tmp/existing_cache.json ] && [ ! -f src/data/acr_criteria.json ]; then
            cp /tmp/existing_cache.json src/data/acr_criteria.json
          fi

      - name: Show stats
        if: steps.need_update.outputs.skip != 'true'
        run: |
          python3 << 'EOF'
          import json
          data = json.load(open("src/data/acr_criteria.json"))
          topics = data.get("topics", {})
          state = data.get("scrape_state", {})

          print(f"Topics: {len(topics)}")
          print(f"Details scraped: {state.get('details_scraped', 0)}")
          print(f"Details blocked: {state.get('details_blocked', 0)}")

          pending = sum(1 for t in topics.values() if t.get('status') in ('pending', 'failed', None))
          print(f"Pending: {pending}")
          EOF

      - name: Check for changes
        if: steps.need_update.outputs.skip != 'true'
        id: check
        run: |
          git add src/data/acr_criteria.json
          if git diff --cached --quiet; then
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push
        if: steps.need_update.outputs.skip != 'true' && steps.check.outputs.changed == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git commit -m "Update ACR cache [$(date +%Y-%m-%d)]"
          git push origin data
